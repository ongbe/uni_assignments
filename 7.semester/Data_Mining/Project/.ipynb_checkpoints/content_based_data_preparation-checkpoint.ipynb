{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LARGE_DATASET = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if LARGE_DATASET:\n",
    "    movie_path = \"ml-latest/movies.csv\"\n",
    "    tags_path = \"ml-latest/tags.csv\"\n",
    "    ratings_path = \"ml-latest/ratings.csv\"\n",
    "    movie_profiles_path = \"/media/karol/E8B625B3B6258364/calculated/movie_profiles\"\n",
    "    user_profiles_path = \"/media/karol/E8B625B3B6258364/calculated/user_profiles/\"\n",
    "else:\n",
    "    movie_path = \"ml-latest-small/movies.csv\"\n",
    "    tags_path = \"ml-latest-small/tags.csv\"\n",
    "    ratings_path = \"ml-latest-small/ratings.csv\"\n",
    "    movie_profiles_path = \"/media/karol/E8B625B3B6258364/calculated-small/movie_profiles\"\n",
    "    user_profiles_path = \"/media/karol/E8B625B3B6258364/calculated-small/user_profiles/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group(data_frame, group_by):\n",
    "    return data_frame.groupby(group_by, as_index = False, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_user_profile(userId):\n",
    "    directory = user_profiles_path + str(userId // 1000) + \"/\" + str(userId)\n",
    "    user_profile = pd.read_csv(directory,  header=None, usecols=[1,2,3])\n",
    "    return user_profile.rename(columns={1:\"tag\",2:\"u_weight\",3:\"userId\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_data = pd.read_csv(movie_path)\n",
    "tags_data = pd.read_csv(tags_path)\n",
    "ratings_data = pd.read_csv(ratings_path)\n",
    "for i in range(tags_data.shape[0]):\n",
    "    tags_data.set_value(i, \"tag\", str(tags_data[\"tag\"][i]).lower())\n",
    "    \n",
    "user_ids = ratings_data['userId'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mvs = tags_data['movieId'].drop_duplicates()\n",
    "unique_tags = tags_data[['tag']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mvs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mf = open(movie_profiles_path, 'r')\n",
    "movie_profiles = pd.read_csv(mf).rename(columns={'weight':'m_weight'})\n",
    "\n",
    "def get_movie_profile(movieId):\n",
    "    return movie_profiles[movie_profiles['movieId'] == movieId]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tags: Calculate TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of times each tag was used to describe each movie\n",
    "movie_tag_count = group(tags_data,['movieId','tag'])\\\n",
    "    .count()                                        \\\n",
    "    .rename(columns = {'userId': 'tag_count'})[['movieId','tag','tag_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distinct_tags = tags_data[['tag','movieId']].drop_duplicates()\n",
    "\n",
    "# number of movies that were described by each tag\n",
    "tags_occurence = group(distinct_tags, ['tag'])\\\n",
    "        .count()                              \\\n",
    "        .rename(columns = {'movieId': 'tag_count'})[['tag','tag_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "document_count = len(tags_data['movieId'].drop_duplicates())\n",
    "\n",
    "DF = tags_occurence\n",
    "DF['IDF'] = np.log10(document_count / DF['tag_count'])\n",
    "\n",
    "TF = movie_tag_count.rename(columns ={'tag_count': 'TF'})\n",
    "\n",
    "TF_IDF = pd.merge(TF, DF, on='tag', how='left', sort=False)\n",
    "TF_IDF['TF-IDF'] = TF_IDF['TF'] * TF_IDF['IDF']\n",
    "TF_IDF = TF_IDF.drop(['TF','IDF', 'tag_count'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tags: Normalize vectors to unit length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# divide vectors dimensions by its length\n",
    "V = TF_IDF.drop('tag',1)\n",
    "V['V'] = (V['TF-IDF']**2)\n",
    "\n",
    "V = group(V,['movieId']).sum().drop(\"TF-IDF\",1)\n",
    "V['V'] = np.sqrt(V[['V']].sum(1))\n",
    "\n",
    "TF_IDF = pd.merge(TF_IDF, V, on='movieId', how = 'left',sort=False)\n",
    "TF_IDF['weight'] = TF_IDF['TF-IDF'] / TF_IDF['V']\n",
    "TF_IDF = TF_IDF.drop(['V','TF-IDF'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saved in a file for later calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TF_IDF.shape\n",
    "f = open(movie_profiles_path, 'w')\n",
    "TF_IDF.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Users: Calculate user profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_data = pd.read_csv(ratings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_ratings = group(ratings_data,['userId'])\n",
    "user_ids = ratings_data[['userId']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "n = 1000;\n",
    "first = True\n",
    "for _, user in user_ids.iterrows():\n",
    "    userId = user['userId']\n",
    "    directory = user_profiles_path + str(userId // 1000)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    f = open(directory + '/' + str(userId), 'w')\n",
    "    ratings = ratings_data[ratings_data['userId'] == userId]\n",
    "    mean = ratings['rating'].mean()\n",
    "    user_data = ratings.drop(['timestamp','userId'],1)\n",
    "    user_data['uweight'] = user_data['rating'] - mean\n",
    "    user_data1 = pd.merge(TF_IDF, user_data,on = 'movieId',how='inner',sort=False)\n",
    "    user_data1['weight'] = user_data1[\"uweight\"] * user_data1['weight']\n",
    "    user_profile = group(user_data1,['tag']).sum()\n",
    "    user_profile = user_profile.drop(['movieId','rating','uweight'], 1)\n",
    "    user_profile['userId'] = userId\n",
    "    user_profile.to_csv(f, mode='a', header=first)\n",
    "    first = False\n",
    "    if userId > n:\n",
    "        n += 1000;\n",
    "        print(time.time() - start)\n",
    "        start = time.time()\n",
    "        print(userId)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "#This took over 3hr's of calculations and generated 36gb of data"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
